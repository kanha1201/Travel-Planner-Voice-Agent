# Voice Travel Planner - Trip Planning Assistant

An AI-powered voice assistant for planning personalized trips to Jaipur, India. The system uses natural language processing, RAG (Retrieval Augmented Generation), and real-time POI search to create customized itineraries based on user preferences.

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Voice Frontend â”‚  (React + TypeScript)
â”‚  (Browser)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/WebSocket
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server â”‚  (Python Backend)
â”‚  (Port 8000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM   â”‚ â”‚  RAG    â”‚  â”‚  POI     â”‚  â”‚  Voice   â”‚
â”‚Orchestrâ”‚ â”‚ System  â”‚  â”‚  Search  â”‚  â”‚ Services â”‚
â”‚        â”‚ â”‚         â”‚  â”‚          â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚              â”‚             â”‚
    â–¼         â–¼              â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  External Services                               â”‚
â”‚  - Cerebras/Groq/Gemini (LLM)                    â”‚
â”‚  - AssemblyAI (Speech-to-Text)                   â”‚
â”‚  - ElevenLabs (Text-to-Speech)                   â”‚
â”‚  - OpenStreetMap (POI Data)                      â”‚
â”‚  - ChromaDB (Vector Database)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### 1. **Frontend** (`voice-frontend/`)
- **Technology**: React 18, TypeScript, Vite, Tailwind CSS
- **Components**:
  - `VoiceChatPage`: Main voice interface with transcript display
  - `ItineraryFeed`: Day-wise itinerary visualization
  - `SourcesModal`: Data sources display
  - `Header`: Navigation and info button
- **Features**:
  - Real-time voice recording and playback
  - Scrollable chat interface
  - Formatted message display (days, time periods, bullet points)
  - Source citations in modal

#### 2. **Backend** (`backend/`)
- **Technology**: FastAPI, Python 3.12+
- **Key Modules**:
  - `api/routes/voice.py`: Voice chat API endpoint
  - `api/routes/trip.py`: Itinerary retrieval endpoint
  - `llm/orchestrator.py`: LLM orchestration with tool calling
  - `llm/cerebras_client.py`: Cerebras LLM integration
  - `llm/groq_client.py`: Groq LLM integration
  - `llm/gemini_client.py`: Gemini LLM integration
  - `tools/poi_search.py`: OpenStreetMap POI search
  - `tools/itinerary_builder.py`: Day-wise itinerary construction
  - `tools/rag_retrieval.py`: RAG-based city guidance retrieval
  - `rag/`: RAG system (data ingestion, chunking, vector store)
  - `voice/`: STT/TTS clients (AssemblyAI, ElevenLabs)
  - `core/session_manager.py`: Session management
  - `core/response_cache.py`: Response caching
  - `core/tool_cache.py`: Tool result caching

#### 3. **LLM Orchestrator**
- **Function Calling**: Supports tool execution with automatic fallback
- **Providers**: Cerebras (primary) â†’ Groq (fallback) â†’ Gemini (last resort)
- **Tools**:
  - `search_pois`: Find points of interest
  - `build_itinerary`: Create structured day-wise plans
  - `retrieve_city_guidance`: Get factual information with citations
  - `ask_clarifying_question`: Generate clarifying questions

#### 4. **RAG System**
- **Vector Database**: ChromaDB with sentence-transformers embeddings
- **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions)
- **Data Sources**: Wikivoyage, Wikipedia
- **Chunking**: ~500 tokens per chunk with overlap
- **Retrieval**: Semantic search with top-k results

#### 5. **Voice Services**
- **STT (Speech-to-Text)**: AssemblyAI (primary), ElevenLabs (alternative)
- **TTS (Text-to-Speech)**: ElevenLabs
- **Audio Format**: WebM (browser) â†’ WAV (converted) â†’ MP3 (response)

## ğŸš€ Setup

### Prerequisites

- **Python**: 3.12 or higher
- **Node.js**: 18+ and npm
- **ffmpeg**: Required for audio conversion (download from https://ffmpeg.org/download.html)
- **API Keys**:
  - Cerebras API key (or Groq/Gemini as fallback)
  - AssemblyAI API key (for STT)
  - ElevenLabs API key (for TTS)

### Backend Setup

1. **Navigate to backend directory**:
   ```bash
   cd backend
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   ```

3. **Activate virtual environment**:
   - **Windows**:
     ```bash
     .\venv\Scripts\activate
     ```
   - **Linux/Mac**:
     ```bash
     source venv/bin/activate
     ```

4. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

5. **Set up environment variables**:
   ```bash
   cp env.example .env
   ```
   Edit `.env` and add your API keys:
   ```env
   CEREBRAS_API_KEY=your_key_here
   ASSEMBLYAI_API_KEY=your_key_here
   ELEVENLABS_API_KEY=your_key_here
   ```

6. **Ingest RAG data** (first time only):
   ```bash
   python -m rag.ingest_pipeline
   ```
   This downloads and processes travel guide data from Wikivoyage and Wikipedia.

7. **Start the server**:
   ```bash
   uvicorn main:app --reload
   ```
   Server runs on `http://localhost:8000`

### Frontend Setup

1. **Navigate to frontend directory**:
   ```bash
   cd voice-frontend
   ```

2. **Install dependencies**:
   ```bash
   npm install
   ```

3. **Start development server**:
   ```bash
   npm run dev
   ```
   Frontend runs on `http://localhost:5173`

### Verify Installation

1. Backend health check: `http://localhost:8000/docs` (FastAPI Swagger UI)
2. Frontend: Open `http://localhost:5173` in browser
3. Test voice chat: Click microphone button and speak

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ voice.py          # Voice chat endpoint
â”‚   â”‚       â””â”€â”€ trip.py           # Itinerary endpoint
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ session_manager.py   # Session management
â”‚   â”‚   â”œâ”€â”€ response_cache.py    # Response caching
â”‚   â”‚   â””â”€â”€ tool_cache.py        # Tool result caching
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # LLM orchestration
â”‚   â”‚   â”œâ”€â”€ cerebras_client.py   # Cerebras LLM client
â”‚   â”‚   â”œâ”€â”€ groq_client.py       # Groq LLM client
â”‚   â”‚   â”œâ”€â”€ gemini_client.py     # Gemini LLM client
â”‚   â”‚   â””â”€â”€ functions.py         # Function definitions
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ poi_search.py         # POI search tool
â”‚   â”‚   â”œâ”€â”€ itinerary_builder.py  # Itinerary builder tool
â”‚   â”‚   â”œâ”€â”€ rag_retrieval.py     # RAG retrieval tool
â”‚   â”‚   â””â”€â”€ register_handlers.py # Tool registration
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py    # Data fetching
â”‚   â”‚   â”œâ”€â”€ chunking.py          # Text chunking
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB management
â”‚   â”‚   â”œâ”€â”€ retrieval.py        # RAG retrieval
â”‚   â”‚   â””â”€â”€ ingest_pipeline.py   # Ingestion pipeline
â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”œâ”€â”€ stt_client.py        # STT client interface
â”‚   â”‚   â”œâ”€â”€ assemblyai_stt_client.py  # AssemblyAI STT
â”‚   â”‚   â”œâ”€â”€ tts_client.py        # TTS client interface
â”‚   â”‚   â””â”€â”€ elevenlabs_tts_client.py  # ElevenLabs TTS
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/                 # Raw data files
â”‚   â”‚   â””â”€â”€ chroma_db/           # Vector database
â”‚   â”œâ”€â”€ main.py                  # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ env.example              # Environment template
â”‚   â””â”€â”€ test_sources.py          # Source testing script
â”‚
â”œâ”€â”€ voice-frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceChatPage.tsx    # Main voice interface
â”‚   â”‚   â”‚   â”œâ”€â”€ ItineraryFeed.tsx    # Itinerary display
â”‚   â”‚   â”‚   â”œâ”€â”€ SourcesModal.tsx     # Sources modal
â”‚   â”‚   â”‚   â””â”€â”€ Header.tsx          # App header
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts               # API client
â”‚   â”‚   â”‚   â”œâ”€â”€ voiceRecorder.ts     # Voice recording
â”‚   â”‚   â”‚   â””â”€â”€ formatMessage.ts    # Message formatting
â”‚   â”‚   â”œâ”€â”€ App.tsx                  # Main app component
â”‚   â”‚   â””â”€â”€ types.ts                 # TypeScript types
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ README.md                      # This file
```

## ğŸ”§ Configuration

### Environment Variables

See `backend/env.example` for all available configuration options.

**Key Variables**:
- `LLM_PROVIDER`: `cerebras`, `groq`, or `gemini` (default: `cerebras`)
- `STT_PROVIDER`: `assemblyai` or `elevenlabs` (default: `assemblyai`)
- `TTS_PROVIDER`: `elevenlabs` (only option currently)
- `LOG_LEVEL`: `DEBUG`, `INFO`, `WARNING`, `ERROR` (default: `INFO`)

### LLM Provider Selection

The system automatically falls back through providers:
1. **Cerebras** (primary) - Fast, reliable
2. **Groq** (fallback) - Fast inference
3. **Gemini** (last resort) - Google's model

Set `LLM_PROVIDER` in `.env` to force a specific provider.

## ğŸ§ª Testing

### Test Sources Generation

Test if sources are being generated correctly:

```bash
cd backend
.\venv\Scripts\activate  # Windows
# or: source venv/bin/activate  # Linux/Mac
python test_sources.py
```

### Manual Testing

1. **Voice Chat**: Use the microphone button to test voice interactions
2. **Itinerary Generation**: Ask "Plan a 2-day trip to Jaipur"
3. **Source Citations**: Click the "i" button to view sources
4. **Itinerary Modifications**: Try "Remove Day 1 morning activity"

## ğŸ“š Documentation

- **Tools**: See [TOOLS.md](TOOLS.md) for detailed tool documentation
- **Datasets**: See [DATASETS.md](DATASETS.md) for data sources
- **Evaluations**: See [EVALS.md](EVALS.md) for evaluation instructions
- **Sample Transcripts**: See [SAMPLE_TRANSCRIPTS.md](SAMPLE_TRANSCRIPTS.md) for test cases

## ğŸ› Troubleshooting

### Common Issues

1. **"ModuleNotFoundError: No module named 'dotenv'"**
   - Solution: Activate virtual environment before running scripts

2. **"ElevenLabs API key error"**
   - Solution: Verify API key in `.env` file, check account credits

3. **"AssemblyAI STT error: File does not appear to contain audio"**
   - Solution: Ensure ffmpeg is installed and in PATH

4. **"Sources not appearing in UI"**
   - Solution: Check browser console for errors, verify backend logs

5. **"LLM provider errors"**
   - Solution: System will auto-fallback to next provider, check API keys

### Debug Mode

Enable debug logging:
```env
LOG_LEVEL=DEBUG
```

## ğŸ“ License

This project is for educational/demonstration purposes.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“§ Support

For issues or questions, please open an issue on the repository.


